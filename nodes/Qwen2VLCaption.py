import os
import sys
import torch
from PIL import Image
from io import BytesIO
import base64
from contextlib import contextmanager
from tenacity import retry, stop_after_attempt, wait_exponential
from http import HTTPStatus
import dashscope

# æ·»åŠ çˆ¶ç›®å½•åˆ° Python è·¯å¾„
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

from ..api_utils import load_api_key

@contextmanager
def temporary_env_var(key: str, new_value):
    old_value = os.environ.get(key)
    os.environ[key] = new_value if new_value is not None else os.environ.pop(key, None)
    try:
        yield
    finally:
        if old_value is not None:
            os.environ[key] = old_value
        elif key in os.environ:
            del os.environ[key]

class QwenVLBase:
    def __init__(self):
        self.api_key = load_api_key('DASHSCOPE_API_KEY')
        if self.api_key:
            dashscope.api_key = self.api_key
        else:
            print("é”™è¯¯ï¼šåœ¨ api_key.ini ä¸­æœªæ‰¾åˆ° DASHSCOPE_API_KEY")

    @staticmethod
    def tensor_to_image(tensor):
        return Image.fromarray(tensor.squeeze().mul(255).clamp(0, 255).byte().cpu().numpy(), mode='RGB')

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def call_api(self, prompt, image, model, task, temperature=0.7, max_tokens=1024):
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()

        messages = [
            {
                "role": "system",
                "content": f"You are an AI assistant specialized in {task}. Analyze the image and respond accordingly."
            },
            {
                "role": "user",
                "content": [
                    {"image": img_str},
                    {"text": prompt}
                ]
            }
        ]

        response = dashscope.MultiModalConversation.call(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        if response.status_code == HTTPStatus.OK:
            return response.output.text
        else:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")

class Qwen2VLCaption(QwenVLBase):
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {"default": "åˆ†æè¿™å¼ å›¾ç‰‡å¹¶æä¾›è¯¦ç»†æè¿°ã€‚", "multiline": True}),
                "model": (["qwen-vl-max-0809", "qwen-vl-max", "qwen-vl-plus", "qwen-vl"], {"default": "qwen-vl-max-0809"}),
                "task": (["general", "ocr", "visual_reasoning", "chinese_understanding", "prompt_generation"], {"default": "general"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 2048}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("result",)
    FUNCTION = "process_image"
    CATEGORY = "ğŸŒ™DW/QwenVL"

    def process_image(self, image, prompt, model, task, temperature, max_tokens):
        if not self.api_key:
            return ("é”™è¯¯ï¼šDASHSCOPE_API_KEY æœªè®¾ç½®æˆ–æ— æ•ˆã€‚è¯·æ£€æŸ¥æ‚¨çš„ api_key.ini æ–‡ä»¶ã€‚",)

        try:
            pil_image = self.tensor_to_image(image)
            
            task_prompts = {
                "general": "åˆ†æè¿™å¼ å›¾ç‰‡å¹¶æä¾›è¯¦ç»†æè¿°ã€‚",
                "ocr": "è¯†åˆ«å¹¶æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ã€‚",
                "visual_reasoning": "åˆ†æå›¾ç‰‡å¹¶å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š",
                "chinese_understanding": "åˆ†æå›¾ç‰‡å¹¶ç”¨æµç•…çš„ä¸­æ–‡æè¿°å†…å®¹ã€‚",
                "prompt_generation": "åˆ†æè¿™å¼ å›¾ç‰‡å¹¶ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ–‡æœ¬åˆ°å›¾åƒæç¤ºã€‚ä¸è¦åŠ å‰ç¼€ï¼"
            }
            
            full_prompt = f"{task_prompts[task]} {prompt}"
            
            with temporary_env_var('HTTP_PROXY', None), temporary_env_var('HTTPS_PROXY', None):
                result = self.call_api(full_prompt, pil_image, model, task, temperature=temperature, max_tokens=max_tokens)
            
            return (result,)
        except Exception as e:
            return (f"é”™è¯¯: {str(e)}",)

NODE_CLASS_MAPPINGS = {
    "Qwen2VLCaption": Qwen2VLCaption,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Qwen2VLCaption": "é€šä¹‰åƒé—®VL å¤šåŠŸèƒ½è§†è§‰åˆ†æ",
}